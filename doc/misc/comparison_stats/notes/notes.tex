\documentclass{article}
\begin{document}

\section{From V\&V by Oberkampf and Roy}

validation metrics - mathematical operators that compute the difference between the experimentally measured results and the simulation results.  V\&V in SC, pg 469 (See also page 473)

type 1 error: model builder's risk.  The error of rejecting the model when the model is actually correct (such as because of comparison with incorrect data) V\&V in SC, pg 481

type 2 error: model user's risk.  The error of accepting validity of the model when the model is actually invalid.  V\&V in SC, pg 482


Comparison of mean values.  V\&V in SC, pg 485.  $L_1$ or $L_2$ vector norms usually used:

\begin{equation}
  \| S - E \|_p = \left(\frac{1}{N}\sum^N_{i=1} | S(x_i) - E(x_i)|^p \right)^\frac{1}{p}
\end{equation}

Comparison of mean with experimental mean and variance. V\&V in SC, pg
493-497.  The goal is to determine the true error based on $\tilde{E}
= y_m - \bar{y}_e$ where $y_m$ is the computed value, $\bar{y}_e$ is
the experimental mean and $\tilde{E}$ is the estimated error.  The
experimental mean is:

\begin{equation}
  \bar{y}_e = \frac{1}{n} \sum^n_{i=1} y^i_e
\end{equation}

The sample standard deviations is:

\begin{equation}
  s = \left[ \frac{1}{n-1} \sum^n_{i=1} (y^i_e - \bar{y}_e)^2 \right ]^\frac{1}{2}
\end{equation}

The interval containing the true error $E = y_m - \mu$ where the level of confidence is $100(1-\alpha)$\% is:

\begin{equation}
  \left ( \tilde{E}-t_{\alpha/2,v}\cdot\frac{s}{\sqrt{n}},\tilde{E}+t_{\alpha/2,v}\cdot\frac{s}{\sqrt{n}}  \right )
\end{equation}

Comparison of means using interpolation of experimental data. V\&V in
SC, pg 500-501.  If there are multiple sets of experimental data that
relate input variables to results, then the interpolation of the sets
can be used for statistics.  The standard deviation can be calculated
as (where the sets of interpolated experimental data are $y^i_e(x)$):

\begin{equation}
  s(x) \sim \left [ \frac{1}{n-1} \sum^n_{i=1}\left ( y^i_e(x) - \bar{y}_e(x) \right ) ^2 \right ] ^\frac{1}{2}
\end{equation}

The true error is in the interval:

\begin{equation}
  \left ( \tilde{E}(x)-t_{\alpha/2,v}\cdot\frac{s(x)}{\sqrt{n}},\tilde{E}(x)+t_{\alpha/2,v}\cdot\frac{s(x)}{\sqrt{n}}  \right )
\end{equation}

I think this may not be very useful because of the number of
assumptions required and the shear amount of data that is required to
get enough $y^i_e$ values.

Comparison of means requiring linear regression of the experimental
data. V\&V in SC, pg 508-510. This is where there are a set of $n$
experimental measurements $(y^i_e,x_i)$.

The linear regression function is:

\begin{equation}
  \bar{y}_e(x) = \theta_1 + x\theta_2+\epsilon
\end{equation}

The estimate interval for the true mean is:

\begin{equation}
  \mu(x) \sim (\bar{y}(x) - SCI(x),\bar{y}(x)+SCI(x))
\end{equation}

Where $SCI(x)$ is the width of the Scheff\'e confidence interval as a function of $x$ and is:

\begin{equation}
  SCI(x) = s\sqrt{[2F(2,n-2,1-\alpha)]\left [ \frac{1}{n}+\frac{(x-\bar{x})^2}{(n-1)s^2_x} \right ] }
\end{equation}

\begin{equation}
  s = \sqrt{\frac{1}{n-1}\sum^n_{i=1}\left [ y^i_e-\bar{y}_e(x_i) \right ]^2}
\end{equation}
\begin{equation}
  \bar{x} = \frac{1}{n}\sum^n_{i=1}x_i
\end{equation}
\begin{equation}
  s^2_x=\frac{1}{n-1}\sum^n_{i=1}(x_i-\bar{x})^2
\end{equation}

\section{From Talking with Cristian}

%2015 March 31

The goal is to be able to tell if the sign of the correlation is
correct.  So say that we have the output variables, and they match in
probability distribution.  It is still a problem if for example the
main cause of the probability change is input i, but in the
experiment, low i causes high output, but in the simulation low i
causes low output, that is, the sign of the correlation is wrong.

This should be similar to the formula used before, but now we have
$P(ex | S)$ instead of just $P(ex)$.  This is the probability of ex
conditional on S.  The probability of the simulation (s) is the
results of the input chosen, the input chosen is related to the
experimental reading via the correlation of the sensors in the
experiments.

\begin{equation}
  \int_{-\infty}^{\infty}dSP(S) \int_{-\infty}^{\infty} dex(S-ex) P(ex | S)
\end{equation}

\section{Goals for 2015}

\begin{itemize}
\item Determine if the correlation between an input and output are the same in the experiment and in the calculated version. If the probability distributions are the same, is the same thing being calculated?
\item Look at the correlation between input and output.
\item Look at examining multiple figures of merit (distance measure?).  Especially if some of the output is correlated.
\item Look at the correlation between inputs.
\item (Optional)Look at time dependent analysis (fourier transforms and such.)
\end{itemize}

\end{document}
