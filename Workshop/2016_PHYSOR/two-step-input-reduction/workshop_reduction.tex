\documentclass[t,9pt,svgnames]{beamer}
\usepackage[latin1]{inputenc}
\usepackage{framed}
\usepackage{graphics}
\usepackage{helvet}
\usepackage{courier}
\usepackage{amsmath}
\usepackage[absolute,overlay]{textpos}
\usepackage{fancybox}
\usepackage{bm} % Use \bm to generate bold math fonts

%%%%% NOTE TO USER %%%%%%%
%
%  This template requires the 'frame-bg.pdf' and 'title-bg.pdf' be found.  It should have been included with
%  this example.
%%%%%%%%%%%%%%%%%%%%%%%%%

\graphicspath{
{graphics/}
}

\usetheme{INL}

\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\scriptsize,
  frame=single,
  backgroundcolor=\color{cbbkng},
  emphstyle={\color{red}\textbf},
	showstringspaces=false,
  commentstyle=\color{inl@green},
	keywordstyle=\bfseries,
  escapeinside=$$
}

\setbeamercolor{codeboxcolor}{fg=white,bg=black}

\definecolor{bubblebkng}{rgb}{0.98,0.98,0}
%\definecolor{cbbkng}{rgb}{0.98,0.9,0.98}
\definecolor{cbbkng}{RGB}{227,233,252}

\newenvironment{codebox}{}{}
% #1 - width
% #2 - position on the page (<dim>,<dim>)
% #3 - text
\newcommand{\bubbleat}[3]{\begin{textblock*}{#1}[1,1](#2)
\fcolorbox{black}{yellow}{%
\scriptsize\begin{Bcenter}
#3
\end{Bcenter}}
\end{textblock*}}

\newcommand{\uo}{\ensuremath{\mbox{UO}_2}}
\newcommand{\mytilde}{\raise.17ex\hbox{$\scriptstyle\sim$}}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\comment}[1]{{\usebeamercolor[fg]{comment code} #1}}

\newenvironment{codelst}{\begin{verbatim}}{\end{verbatim}}

\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\red}[1]{{\color{red}#1}}

% TOC
\newdimen\tocpnumwd
\tocpnumwd=30pt

\makeatletter

\def\dottedtocline#1#2#3{\bgroup%
  \advance\leftskip by #1%
  \advance\rightskip by #2%
  \advance\rightskip by \tocpnumwd%
  \leaders\hbox to 1.5em{\hss .\hss}\hfill\nobreak%
  \rlap{\hbox to \tocpnumwd{\hfil #3}}\par\egroup}

%\def\beamer@sectionintoc #1#2#3#4#5{{\small#2\dottedtocline{7em}{6em}{#3}}\par}
\def\beamer@sectionintoc #1#2#3#4#5{{\hspace{5em}\hyperlink{Navigation#3}{\small#2\dotfill{#3}}\hspace*{4em}}\par}


%\def\beamer@subsectionintoc %#1#2#3#4#5#6{{\small#3\dottedtocline{9em}{6em}{#4}}\par}
\def\beamer@subsectionintoc #1#2#3#4#5#6{{\hspace{6em}\hyperlink{Navigation#4}{\small#3\dotfill{#4}}\hspace*{4em}}\par}

\newcommand{\mytoc}{\@starttoc{toc}}

\makeatother

%This is an ugly hack to fix a bug with Beamer that doesn't put enough vertical
%space above the first list environment in a columns environment when the [t]
%option is passed to the beamer class.  Use this command somewhere in the
%column before using a list or itemize
\newcommand{\vspacehack}{
\setbox0=\vbox{
\begin{itemize}
\item
\end{itemize}
}}


\begin{document}

% user start editing here! %
\title[RAVEN Workshop]{RAVEN Workshop}
\subtitle{Multi-Step Input Space Reduction}
\institute[INL]{Nuclear Engineering Methods Development Department\\
Idaho National Laboratory}

\begin{titleframe}{RAVEN Workshop}

{\bfseries\emph{Multi-Step Input Reduction}}

\vfill
{\small Nuclear Engineering Methods Development Department\\
Idaho National Laboratory}
\end{titleframe}

\begin{frame}{Discussion Points}
\mytoc
\end{frame}

%                  %
%     OVERVIEW     %
%                  %
\section{Overview}
\begin{frame}{Overview}
\end{frame}

\begin{frame}{Overview: Uncertainty Quantification}
  Benefits:
  \begin{itemize}
    \item Quantity of Interest Variance
    \item Failure Probabilities
    \item Limit Surface Construction
    \item Design of Experiment
  \end{itemize}
\end{frame}

\begin{frame}{Overview: Session Goal}
  Reduce high-dimension input spaces
  \begin{itemize}
    \item Use PCA to eliminate correlated inputs
    \item Use sensitivity to eliminate low-impact inputs
    \item Accurate UQ on a reduced input space
  \end{itemize}
\end{frame}

\begin{frame}{Overview: Assumptions}
  \begin{itemize}
    \item Simulation codes are expensive to run
    \item All inputs are initially perturbable
    \item Saving time and money is good
  \end{itemize}
\end{frame}

%                  %
%    MOTIVATIONS   %
%                  %
\section{Motivations}
\begin{frame}{Motivations}
\end{frame}

\begin{frame}{Motivations: Sampling Strategies}
  Two classes of forward sampling strategies in RAVEN:
  \begin{itemize}
    \item Structured (Orthogonal Grids, Limit Surface, Latin Hypercube)
    \item Unstructured (Monte Carlo)
  \end{itemize}
  %TODO add pictures!
\end{frame}

\begin{frame}{Motivations: Unstructured Sampling}
  Traditional Monte Carlo sampling
  \begin{itemize}
    \item Agnostic of Dimensionality
    \item Consistent, but slow convergence
  \end{itemize}
\end{frame}

\begin{frame}{Motivations: Structured Sampling}
  \code{RAVEN} has several structured solvers
  \begin{itemize}
    \item Orthogonal Grids
    \item Sparse Grid
    \item Stratified
    \item Limit Surface Search
  \end{itemize}
  %TODO split these into individual slides
  All of these suffer from the Curse of Dimensionality
\end{frame}

\begin{frame}{Motivations: Proposed Solution}
  Remove unnecessary input dimensions
  \begin{itemize}
    \item Correlated inputs have redundancy
    \item Low-impact inputs aren't useful to perturb
  \end{itemize}
  Perform UQ on reduced space
\end{frame}
%                  %
%      METHODS     %
%                  %
\section{Methods}
\begin{frame}{Methods}
\end{frame}

\begin{frame}{Methods: Procedure Overview}
  \begin{itemize}
    \item (optional) Benchmark original problem
    \item Perform PCA on original input space
    \item Truncate to essential latent variables
    \item Perform global sensitivity analysis
    \item Truncate latent variables to exclude non-essential
  \end{itemize}
\end{frame}

\subsection{Principle Component Analysis}
\begin{frame}{Methods: Principal Component Analysis}
\end{frame}

\begin{frame}{Methods: Principal Component Analysis}
  Used to orthogonalize input space

  Represent input space as sum of ``latent'' variables $\bm{L}$
  \begin{equation}
    \bm{M} = \bm{Q} \cdot \bm{L},
  \end{equation}
  where
  \begin{itemize}
    \item $\bm{M}$ is the vector of original variables, $|M|\times1$,
    \item $\bm{Q}$ is the PCA transformation matrix, $|M|\times |L|$,
    \item $\bm{L}$ is the vector of latent variables, $|L|\times 1$
  \end{itemize}
  All $\bm{L}$ are distributed as standard normal distributions
\end{frame}

\begin{frame}{Methods: Principal Component Analysis}
  \begin{equation}
    \bm{M} = \bm{Q} \cdot \bm{L},
  \end{equation}
  Perform eigenvalue decomposition of covariance matrix and rank eigenvalues

  Truncate latent variables at desirable eigenvalue
  %TODO show list and truncation pic
\end{frame}

\begin{frame}[fragile]{Methods: PCA in RAVEN}
Add transformation to \code{Sampler}:
\begin{codebox}
  \begin{lstlisting}[emph={variablesTransformation,latentVariables,manifestVariables}]
    <Samplers>
      <MonteCarlo name='mc'>
        ... TODO add variables with dimensions
        <variablesTransformation distribution='MultivariateNormalReduction'>
          <latentVariables>y1,y2,y3,y4,y5,y6,y7</latentVariables>
          <manifestVariables>x1,x2,x3,x4,x5,x6,x7</manifestVariables>
          <method>pca</method>
      </MonteCarlo>
    </Samplers>
\end{lstlisting}
\end{codebox}
\end{frame}

\begin{frame}[fragile]{Methods: PCA in RAVEN}
  Use a PostProcessor to extract the rankings

  PostProcessor
  \begin{codebox}
    \begin{lstlisting}[emph={PostProcessor}]
    <Models>
      <PostProcessor TODO>
      </PostProcessor>
    </Models>
    \end{lstlisting}
  \end{codebox}
  Step
  \begin{codebox}
    \begin{lstlisting}[emph={PostProcessor}]
    <Steps>
      <PostProcessor name='TODO'>
      </PostProcessor>
    </Steps>
    \end{lstlisting}
  \end{codebox}
Use results from file TODO to pick PCA truncation
\end{frame}

\begin{frame}[fragile]{Methods: PCA in RAVEN}
  Once reduction level is decided, change sampler truncation
\begin{codebox}
  \begin{lstlisting}[emph={y1,y2,y3}]
    <Samplers>
      <MonteCarlo name='mc'>
        ... TODO add variables with dimensions
        <variablesTransformation distribution='MultivariateNormalReduction'>
          <latentVariables>y1,y2,y3,y4</latentVariables>
          <manifestVariables>x1,x2,x3,x4,x5,x6,x7</manifestVariables>
          <method>pca</method>
      </MonteCarlo>
    </Samplers>
\end{lstlisting}
\end{codebox}
\end{frame}



\subsection{Global Sensitivity Analysis}
\begin{frame}{Methods: Global Sensitivity Analysis}
  Now that we've reduced the input, we can do global sensitivity analysis
  \begin{itemize}
    \item Pearson Correlation Coefficients
    \item Spearman Rank Coefficients
    \item Sobol Sensitivity Coefficients
  \end{itemize}
  Pearson and Spearman can be sampled using forward samplers

  Linear Sobol expansion often more efficient (1 run per latent variable)
\end{frame}

\begin{frame}{Methods: Global Sensitivity Analysis}
  Pearson Coefficients
  \begin{itemize}
    \item Global correlation between dimensions
    \item Can be input-input, input-output, or output-output
    \item Can be calculated using most RAVEN Samplers
  \end{itemize}
  %TODO add picture
\end{frame}

\begin{frame}[fragile]{Methods: Global Sensitivity Analysis}
  More on Sobol sampler and HDMRRom in Collocation workshop!

  Sobol sampler
  \begin{codebox}
    \begin{lstlisting}[emph={y1,y2,y3,Sobol,rom}]
        <Samplers>
          <Sobol name='sobol'>
            ... TODO add variables with dimensions
            <ROM class='Models' type='HDMRRom'>rom</ROM>
            <variablesTransformation distribution='MultivariateNormalReduction'>
              <latentVariables>y1,y2,y3,y4</latentVariables>
              <manifestVariables>x1,x2,x3,x4,x5,x6,x7</manifestVariables>
              <method>pca</method>
          </Sobol>
        </Samplers>
    \end{lstlisting}
  \end{codebox}
\end{frame}

\begin{frame}[fragile]{Methods: Global Sensitivity Analysis}
  HDMRRom
  \begin{codebox}
    \begin{lstlisting}[emph={SobolOrder}]
        <Models>
          <ROM name='rom' subType='HDMRRom'>
            <SobolOrder>1</SobolOrder>
            <PolynomialOrder>1</PolynomialOrder>
            <IndexSet>TotalDegree</IndexSet>
            <Features>y1,y2,y3</Features>
            <Targets>QoI</Targets>
            ... TODO
          </ROM>
        </Models>
    \end{lstlisting}
  \end{codebox}
  ROM Output
  \begin{codebox}
    \begin{lstlisting}[emph={print\_rom,rom}]
      <OutStreams>
        <Print name='print_rom'>
          <type>xml</type>
          <source>rom</source>
          <what>indices</what>
        </Print>
      </OutStreams>
    \end{lstlisting}
  \end{codebox}
\end{frame}

\begin{frame}[fragile]{Methods: Global Sensitivity Analysis}
  Steps
  \begin{codebox}
    \begin{lstlisting}[emph={MultiRun,rom,sobol,RomTrainer,training\_data,rom}]
      <Steps>
        <MultiRun name='sample'>
          <Input class='Files' type=''>infile</Input>
          <Sampler class='Sampelrs' type='Sobol'>sobol</Sampler>
          <Model class='Models' type='ROM'>rom</Models>
          <Output class='DataObjects' type='PointSet'>training_data</Output>
        </MultiRun>
        <RomTrainer name='train'>
          <Input class='DataObjects' type='PointSet'>training_data</Input>
          <Output class='Models' type='ROM'>rom</Input>
        </RomTrainer>
      </Steps>
    \end{lstlisting}
  \end{codebox}
\end{frame}

\begin{frame}[fragile]{Methods: Global Sensitivity Analysis}
  Output from ROM
  \begin{codebox}
    \begin{lstlisting}[emph={indices}]
    <ROM>
      <QoI>
        <indices>
          <tot\_variance>TODO</tot\_variance>
          <variables>TODO
            <partial\_variance>TODO</partial\_variance>
            <Sobol\_index>TODO</Sobol\_index>
          </variables>
        </indices>
      </QoI>
    </ROM>
    \end{lstlisting}
  \end{codebox}
\end{frame}

\subsection{Twice-Reduced Space}
\begin{frame}[fragile]{Methods: Twice-Reduced Analysis}
  Change dimensions in Sampler to prioritize
  \begin{codebox}
    \begin{lstlisting}[emph={indices}]
      TODO sampler
    \end{lstlisting}
  \end{codebox}
\end{frame}

\begin{frame}[fragile]{Methods: Twice-Reduced Analysis}
  Now what?
  \begin{itemize}
    \item Make a ROM
    \item Perform surrogate statistics sampling
    \item Compute limit surface on surrogate
  \end{itemize}
\end{frame}

\section{Full Example}
\begin{frame}[fragile]{Full Example}
  Example case: Cross Section Model
  \begin{itemize}
    \item 308 Correlated Cross Sections (SCALE)
    \item Simulation model is polynomial combinations
    \item PCA Reduction: 308 to 50
    \item Sensitivity Reduction: 50 to 9
  \end{itemize}
  See included examples:
  \begin{itemize}
    \item Original Monte Carlo benchmark: \code{run\char`_mc\char`_orig.xml}
    \item PCA reduction: \code{run\char`_mc\char`_pca.xml}
    \item PCA output: \code{first/TODO}
    \item Sensitivity reduction: \code{run\char`_mc2\char`_[\#].xml}
    \item Sensitivity output: \code{first/sobol\char`_dump.xml}
    \item ROM with twice-reduced space: \code{sc\char`_td[\#].xml}
    \item Twice-reduced output: \code{td\char`_[\#]\char`_dump.xml}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Full Example: Results}
  TODO RESULTS PLOTS
\end{frame}

\end{document}

